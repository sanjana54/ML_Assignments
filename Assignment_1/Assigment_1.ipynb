{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c8BUGQtxbi6n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vRKNqq9Zbi6p",
        "outputId": "cca4fd2f-ea54-47c0-ec14-44c74442caae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1341 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1341/1341 [00:39<00:00, 34.01it/s]\n",
            "100%|██████████| 3875/3875 [01:42<00:00, 37.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NORMAL: 1341\n",
            "PNEUMONIA: 3875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 234/234 [00:02<00:00, 86.45it/s] \n",
            "100%|██████████| 390/390 [00:06<00:00, 58.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NORMAL: 1575\n",
            "PNEUMONIA: 4265\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 47.16it/s]\n",
            "100%|██████████| 8/8 [00:00<00:00, 43.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NORMAL: 1583\n",
            "PNEUMONIA: 4273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "REBUILD_DATA = True # set to true to one once, then back to false unless you want to change something in your training data.\n",
        "\n",
        "class PNEUMONIA_DETECTOR():\n",
        "    IMG_SIZE = 50\n",
        "    NORMAL = \"NORMAL\"\n",
        "    PNEUMONIA = \"PNEUMONIA\"\n",
        "    dir = {\n",
        "        \"train\": {\n",
        "            NORMAL: \"train/NORMAL\",\n",
        "            PNEUMONIA: \"train/PNEUMONIA\"\n",
        "        },\n",
        "        \"test\": {\n",
        "            NORMAL: \"test/NORMAL\",\n",
        "            PNEUMONIA: \"test/PNEUMONIA\"\n",
        "        },\n",
        "        \"val\": {\n",
        "            NORMAL: \"val/NORMAL\",\n",
        "            PNEUMONIA: \"val/PNEUMONIA\"\n",
        "        },\n",
        "    }\n",
        "\n",
        "    LABELS = {NORMAL: 0, PNEUMONIA: 1}\n",
        "\n",
        "    normalcount = 0\n",
        "    pneumoniacount = 0\n",
        "\n",
        "    def make_data(self, type):\n",
        "        training_data = []\n",
        "        for label, dir in self.dir[type].items():\n",
        "            for f in tqdm(os.listdir(dir)):\n",
        "                if \"jpeg\" in f:\n",
        "                    try:\n",
        "                        path = os.path.join(dir, f)\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                        training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot\n",
        "                        #print(np.eye(2)[self.LABELS[label]])\n",
        "                        # print(len(self.training_data), len(self.training_data[-1][0]), len(self.training_data[-1][1]), self.training_data[-1])\n",
        "                        if label == self.NORMAL:\n",
        "                            self.normalcount += 1\n",
        "                        elif label == self.PNEUMONIA:\n",
        "                            self.pneumoniacount += 1\n",
        "\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "                        pass\n",
        "                        #print(label, f, str(e))\n",
        "\n",
        "        training_data = np.array(training_data, dtype=\"object\")\n",
        "\n",
        "        np.random.shuffle(training_data)\n",
        "        np.save(type+\"_data.npy\", training_data, allow_pickle=True)\n",
        "        print('NORMAL:',self.normalcount)\n",
        "        print('PNEUMONIA:',self.pneumoniacount)\n",
        "\n",
        "if REBUILD_DATA:\n",
        "    predictor = PNEUMONIA_DETECTOR()\n",
        "    predictor.make_data(\"train\")\n",
        "    predictor.make_data(\"test\")\n",
        "    predictor.make_data(\"val\")\n",
        "    # print(dogsvcats.training_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTizhwBkbi6q",
        "outputId": "7230fc40-b8f7-4071-ad77-2a870de2910f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5216\n",
            "624\n",
            "16\n"
          ]
        }
      ],
      "source": [
        "training_data = np.load(\"train_data.npy\", allow_pickle=True)\n",
        "testing_data = np.load(\"test_data.npy\", allow_pickle=True)\n",
        "validation_data = np.load(\"val_data.npy\", allow_pickle=True)\n",
        "print(len(training_data))\n",
        "print(len(testing_data))\n",
        "print(len(validation_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5E_7TGTbi6q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MpjDZtKbi6q"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # just run the init of parent class (nn.Module)\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "\n",
        "        x = torch.randn(50,50).view(-1,1,50,50)\n",
        "        self._to_linear = None\n",
        "        self.convs(x)\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
        "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat)\n",
        "\n",
        "    def convs(self, x):\n",
        "        # max pooling over 2x2\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
        "\n",
        "        if self._to_linear is None:\n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
        "        return F.softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aScFmTaIbi6r",
        "outputId": "7f838fb5-f144-4787-c8a4-3f4e003dd588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxrGoP6obi6r",
        "outputId": "24a922cb-6eeb-4a99-92e7-533216490a03"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_24500/4242875165.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpaWMFRfbi6s"
      },
      "outputs": [],
      "source": [
        "train_X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
        "train_X = train_X/255.0\n",
        "train_y = torch.Tensor([i[1] for i in training_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcReRybMbi6s"
      },
      "outputs": [],
      "source": [
        "test_X = torch.Tensor([i[0] for i in testing_data]).view(-1,50,50)\n",
        "test_X = test_X/255.0\n",
        "test_Y = torch.Tensor([i[1] for i in testing_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzfAYyhzbi6s"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 100\n",
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
        "        #print(f\"{i}:{i+BATCH_SIZE}\")\n",
        "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
        "        batch_y = train_y[i:i+BATCH_SIZE]\n",
        "\n",
        "        net.zero_grad()\n",
        "\n",
        "        outputs = net(batch_X)\n",
        "        loss = loss_function(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()    # Does the update\n",
        "\n",
        "    print(f\"Epoch: {epoch}. Loss: {loss}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
